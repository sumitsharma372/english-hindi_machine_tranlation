{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":441417,"sourceType":"datasetVersion","datasetId":200079}],"dockerImageVersionId":25160,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport os\nimport string\nfrom string import digits\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport re\n\nimport seaborn as sns\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom keras.layers import Input, LSTM, Embedding, Dense\nfrom keras.models import Model\n\nprint(os.listdir(\"../input\"))\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\npd.set_option('display.max_colwidth', -1)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-27T09:33:23.210892Z","iopub.execute_input":"2024-06-27T09:33:23.211225Z","iopub.status.idle":"2024-06-27T09:33:23.220083Z","shell.execute_reply.started":"2024-06-27T09:33:23.211178Z","shell.execute_reply":"2024-06-27T09:33:23.219394Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"['Hindi_English_Truncated_Corpus.csv']\n","output_type":"stream"}]},{"cell_type":"code","source":"lines=pd.read_csv(\"../input/Hindi_English_Truncated_Corpus.csv\",encoding='utf-8')","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2024-06-27T09:33:25.005704Z","iopub.execute_input":"2024-06-27T09:33:25.006157Z","iopub.status.idle":"2024-06-27T09:33:25.925927Z","shell.execute_reply.started":"2024-06-27T09:33:25.005940Z","shell.execute_reply":"2024-06-27T09:33:25.925077Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"lines['source'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:33:31.009150Z","iopub.execute_input":"2024-06-27T09:33:31.009431Z","iopub.status.idle":"2024-06-27T09:33:31.049779Z","shell.execute_reply.started":"2024-06-27T09:33:31.009390Z","shell.execute_reply":"2024-06-27T09:33:31.048966Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"tides        50000\nted          39881\nindic2012    37726\nName: source, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"lines=lines[lines['source']=='ted']","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:33:31.809946Z","iopub.execute_input":"2024-06-27T09:33:31.810262Z","iopub.status.idle":"2024-06-27T09:33:31.855829Z","shell.execute_reply.started":"2024-06-27T09:33:31.810221Z","shell.execute_reply":"2024-06-27T09:33:31.855119Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"lines.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:33:32.584672Z","iopub.execute_input":"2024-06-27T09:33:32.585018Z","iopub.status.idle":"2024-06-27T09:33:32.602388Z","shell.execute_reply.started":"2024-06-27T09:33:32.584946Z","shell.execute_reply":"2024-06-27T09:33:32.601635Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"   source                                                  english_sentence                                                        hindi_sentence\n0   ted    politicians do not have permission to do what needs to be done.   राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह करने कि अनुमति नहीं है .\n1   ted    I'd like to tell you about one such child,                        मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहूंगी,                  \n3   ted    what we really mean is that they're bad at not paying attention.  हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते                      \n7   ted    And who are we to say, even, that they are wrong                  और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं                    \n13  ted    So there is some sort of justice                                  तो वहाँ न्याय है                                                    \n23  ted    This changed slowly                                               धीरे धीरे ये सब बदला                                                \n26  ted    were being produced.                                              उत्पन्न नहीं कि जाती थी.                                            \n30  ted    And you can see, this LED is going to glow.                       और जैसा आप देख रहे है, ये एल.ई.डी. जल उठेगी।                        \n32  ted    to turn on the lights or to bring him a glass of water,           लाईट जलाने के लिए या उनके लिए पानी लाने के लिए,                     \n35  ted    Can you imagine saying that?                                      क्या आप ये कल्पना कर सकते है                                        ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>english_sentence</th>\n      <th>hindi_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ted</td>\n      <td>politicians do not have permission to do what needs to be done.</td>\n      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह करने कि अनुमति नहीं है .</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ted</td>\n      <td>I'd like to tell you about one such child,</td>\n      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहूंगी,</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ted</td>\n      <td>what we really mean is that they're bad at not paying attention.</td>\n      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ted</td>\n      <td>And who are we to say, even, that they are wrong</td>\n      <td>और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>ted</td>\n      <td>So there is some sort of justice</td>\n      <td>तो वहाँ न्याय है</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>ted</td>\n      <td>This changed slowly</td>\n      <td>धीरे धीरे ये सब बदला</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>ted</td>\n      <td>were being produced.</td>\n      <td>उत्पन्न नहीं कि जाती थी.</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>ted</td>\n      <td>And you can see, this LED is going to glow.</td>\n      <td>और जैसा आप देख रहे है, ये एल.ई.डी. जल उठेगी।</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>ted</td>\n      <td>to turn on the lights or to bring him a glass of water,</td>\n      <td>लाईट जलाने के लिए या उनके लिए पानी लाने के लिए,</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>ted</td>\n      <td>Can you imagine saying that?</td>\n      <td>क्या आप ये कल्पना कर सकते है</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"pd.isnull(lines).sum()","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:33:33.361143Z","iopub.execute_input":"2024-06-27T09:33:33.361427Z","iopub.status.idle":"2024-06-27T09:33:33.383095Z","shell.execute_reply.started":"2024-06-27T09:33:33.361387Z","shell.execute_reply":"2024-06-27T09:33:33.382314Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"source              0\nenglish_sentence    0\nhindi_sentence      0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"lines=lines[~pd.isnull(lines['english_sentence'])]","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:33:34.110622Z","iopub.execute_input":"2024-06-27T09:33:34.110942Z","iopub.status.idle":"2024-06-27T09:33:34.122913Z","shell.execute_reply.started":"2024-06-27T09:33:34.110883Z","shell.execute_reply":"2024-06-27T09:33:34.122203Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"lines.drop_duplicates(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:33:34.880727Z","iopub.execute_input":"2024-06-27T09:33:34.881052Z","iopub.status.idle":"2024-06-27T09:33:34.929474Z","shell.execute_reply.started":"2024-06-27T09:33:34.880992Z","shell.execute_reply":"2024-06-27T09:33:34.928755Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"lines=lines.sample(n=25000,random_state=42)\nlines.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:33:36.306028Z","iopub.execute_input":"2024-06-27T09:33:36.306320Z","iopub.status.idle":"2024-06-27T09:33:36.320343Z","shell.execute_reply.started":"2024-06-27T09:33:36.306278Z","shell.execute_reply":"2024-06-27T09:33:36.319443Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"(25000, 3)"},"metadata":{}}]},{"cell_type":"code","source":"# Lowercase all characters\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: x.lower())\nlines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.lower())","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:33:36.964705Z","iopub.execute_input":"2024-06-27T09:33:36.965016Z","iopub.status.idle":"2024-06-27T09:33:37.011673Z","shell.execute_reply.started":"2024-06-27T09:33:36.964947Z","shell.execute_reply":"2024-06-27T09:33:37.011092Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Remove quotes\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\nlines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\"'\", '', x))","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:33:37.330728Z","iopub.execute_input":"2024-06-27T09:33:37.331018Z","iopub.status.idle":"2024-06-27T09:33:37.429098Z","shell.execute_reply.started":"2024-06-27T09:33:37.330960Z","shell.execute_reply":"2024-06-27T09:33:37.428490Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"exclude = set(string.punctuation) # Set of all special characters\n# Remove all the special characters\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\nlines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:33:37.619878Z","iopub.execute_input":"2024-06-27T09:33:37.620208Z","iopub.status.idle":"2024-06-27T09:33:38.033382Z","shell.execute_reply.started":"2024-06-27T09:33:37.620151Z","shell.execute_reply":"2024-06-27T09:33:38.032619Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Remove all numbers from text\nremove_digits = str.maketrans('', '', digits)\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: x.translate(remove_digits))\nlines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.translate(remove_digits))\n\nlines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n\n# Remove extra spaces\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: x.strip())\nlines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.strip())\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\nlines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:33:38.034815Z","iopub.execute_input":"2024-06-27T09:33:38.035086Z","iopub.status.idle":"2024-06-27T09:33:38.561038Z","shell.execute_reply.started":"2024-06-27T09:33:38.035031Z","shell.execute_reply":"2024-06-27T09:33:38.560263Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Add start and end tokens to target sequences\nlines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x : 'START_ '+ x + ' _END')","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:33:38.562801Z","iopub.execute_input":"2024-06-27T09:33:38.563135Z","iopub.status.idle":"2024-06-27T09:33:38.583739Z","shell.execute_reply.started":"2024-06-27T09:33:38.563077Z","shell.execute_reply":"2024-06-27T09:33:38.582830Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"lines.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:33:38.629390Z","iopub.execute_input":"2024-06-27T09:33:38.629647Z","iopub.status.idle":"2024-06-27T09:33:38.640225Z","shell.execute_reply.started":"2024-06-27T09:33:38.629604Z","shell.execute_reply":"2024-06-27T09:33:38.639347Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"       source                                                                           english_sentence                                                                                            hindi_sentence\n82040   ted    we still dont know who her parents are who she is                                          START_ हम अभी तक नहीं जानते हैं कि उसके मातापिता कौन हैं वह कौन है _END                                 \n85038   ted    no keyboard                                                                                START_ कोई कुंजीपटल नहीं _END                                                                           \n58018   ted    but as far as being a performer                                                            START_ लेकिन एक कलाकार होने के साथ _END                                                                 \n74470   ted    and this particular balloon                                                                START_ और यह खास गुब्बारा _END                                                                          \n122330  ted    and its not as hard as you think integrate climate solutions into all of your innovations  START_ और जितना आपको लगता है यह उतना कठिन नहीं हैअपने सभी नवाचारों में जलवायु समाधान को एकीकृत करें _END","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>english_sentence</th>\n      <th>hindi_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>82040</th>\n      <td>ted</td>\n      <td>we still dont know who her parents are who she is</td>\n      <td>START_ हम अभी तक नहीं जानते हैं कि उसके मातापिता कौन हैं वह कौन है _END</td>\n    </tr>\n    <tr>\n      <th>85038</th>\n      <td>ted</td>\n      <td>no keyboard</td>\n      <td>START_ कोई कुंजीपटल नहीं _END</td>\n    </tr>\n    <tr>\n      <th>58018</th>\n      <td>ted</td>\n      <td>but as far as being a performer</td>\n      <td>START_ लेकिन एक कलाकार होने के साथ _END</td>\n    </tr>\n    <tr>\n      <th>74470</th>\n      <td>ted</td>\n      <td>and this particular balloon</td>\n      <td>START_ और यह खास गुब्बारा _END</td>\n    </tr>\n    <tr>\n      <th>122330</th>\n      <td>ted</td>\n      <td>and its not as hard as you think integrate climate solutions into all of your innovations</td>\n      <td>START_ और जितना आपको लगता है यह उतना कठिन नहीं हैअपने सभी नवाचारों में जलवायु समाधान को एकीकृत करें _END</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"### Get English and Hindi Vocabulary\nall_eng_words=set()\nfor eng in lines['english_sentence']:\n    for word in eng.split():\n        if word not in all_eng_words:\n            all_eng_words.add(word)\n\nall_hindi_words=set()\nfor hin in lines['hindi_sentence']:\n    for word in hin.split():\n        if word not in all_hindi_words:\n            all_hindi_words.add(word)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:33:38.996656Z","iopub.execute_input":"2024-06-27T09:33:38.996924Z","iopub.status.idle":"2024-06-27T09:33:39.133478Z","shell.execute_reply.started":"2024-06-27T09:33:38.996883Z","shell.execute_reply":"2024-06-27T09:33:39.132882Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"len(all_eng_words)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:33:39.536449Z","iopub.execute_input":"2024-06-27T09:33:39.536709Z","iopub.status.idle":"2024-06-27T09:33:39.541379Z","shell.execute_reply.started":"2024-06-27T09:33:39.536670Z","shell.execute_reply":"2024-06-27T09:33:39.540652Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"14030"},"metadata":{}}]},{"cell_type":"code","source":"len(all_hindi_words)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:33:40.020172Z","iopub.execute_input":"2024-06-27T09:33:40.020440Z","iopub.status.idle":"2024-06-27T09:33:40.025615Z","shell.execute_reply.started":"2024-06-27T09:33:40.020400Z","shell.execute_reply":"2024-06-27T09:33:40.024925Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"17540"},"metadata":{}}]},{"cell_type":"code","source":"lines['length_eng_sentence']=lines['english_sentence'].apply(lambda x:len(x.split(\" \")))\nlines['length_hin_sentence']=lines['hindi_sentence'].apply(lambda x:len(x.split(\" \")))","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:33:40.469891Z","iopub.execute_input":"2024-06-27T09:33:40.470199Z","iopub.status.idle":"2024-06-27T09:33:40.556483Z","shell.execute_reply.started":"2024-06-27T09:33:40.470154Z","shell.execute_reply":"2024-06-27T09:33:40.555919Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"lines.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:33:40.870940Z","iopub.execute_input":"2024-06-27T09:33:40.871261Z","iopub.status.idle":"2024-06-27T09:33:40.883998Z","shell.execute_reply.started":"2024-06-27T09:33:40.871216Z","shell.execute_reply":"2024-06-27T09:33:40.883053Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"       source                                                                           english_sentence                                                                                            hindi_sentence  length_eng_sentence  length_hin_sentence\n82040   ted    we still dont know who her parents are who she is                                          START_ हम अभी तक नहीं जानते हैं कि उसके मातापिता कौन हैं वह कौन है _END                                   11                   16                 \n85038   ted    no keyboard                                                                                START_ कोई कुंजीपटल नहीं _END                                                                             2                    5                  \n58018   ted    but as far as being a performer                                                            START_ लेकिन एक कलाकार होने के साथ _END                                                                   7                    8                  \n74470   ted    and this particular balloon                                                                START_ और यह खास गुब्बारा _END                                                                            4                    6                  \n122330  ted    and its not as hard as you think integrate climate solutions into all of your innovations  START_ और जितना आपको लगता है यह उतना कठिन नहीं हैअपने सभी नवाचारों में जलवायु समाधान को एकीकृत करें _END  16                   20                 ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>english_sentence</th>\n      <th>hindi_sentence</th>\n      <th>length_eng_sentence</th>\n      <th>length_hin_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>82040</th>\n      <td>ted</td>\n      <td>we still dont know who her parents are who she is</td>\n      <td>START_ हम अभी तक नहीं जानते हैं कि उसके मातापिता कौन हैं वह कौन है _END</td>\n      <td>11</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>85038</th>\n      <td>ted</td>\n      <td>no keyboard</td>\n      <td>START_ कोई कुंजीपटल नहीं _END</td>\n      <td>2</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>58018</th>\n      <td>ted</td>\n      <td>but as far as being a performer</td>\n      <td>START_ लेकिन एक कलाकार होने के साथ _END</td>\n      <td>7</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>74470</th>\n      <td>ted</td>\n      <td>and this particular balloon</td>\n      <td>START_ और यह खास गुब्बारा _END</td>\n      <td>4</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>122330</th>\n      <td>ted</td>\n      <td>and its not as hard as you think integrate climate solutions into all of your innovations</td>\n      <td>START_ और जितना आपको लगता है यह उतना कठिन नहीं हैअपने सभी नवाचारों में जलवायु समाधान को एकीकृत करें _END</td>\n      <td>16</td>\n      <td>20</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"lines[lines['length_eng_sentence']>30].shape","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:33:41.332933Z","iopub.execute_input":"2024-06-27T09:33:41.333299Z","iopub.status.idle":"2024-06-27T09:33:41.341781Z","shell.execute_reply.started":"2024-06-27T09:33:41.333241Z","shell.execute_reply":"2024-06-27T09:33:41.340791Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"(0, 5)"},"metadata":{}}]},{"cell_type":"code","source":"lines=lines[lines['length_eng_sentence']<=20]\nlines=lines[lines['length_hin_sentence']<=20]","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:33:41.835478Z","iopub.execute_input":"2024-06-27T09:33:41.835753Z","iopub.status.idle":"2024-06-27T09:33:41.846613Z","shell.execute_reply.started":"2024-06-27T09:33:41.835712Z","shell.execute_reply":"2024-06-27T09:33:41.845785Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"lines.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:33:42.363027Z","iopub.execute_input":"2024-06-27T09:33:42.363348Z","iopub.status.idle":"2024-06-27T09:33:42.368544Z","shell.execute_reply.started":"2024-06-27T09:33:42.363289Z","shell.execute_reply":"2024-06-27T09:33:42.367814Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"(24774, 5)"},"metadata":{}}]},{"cell_type":"code","source":"print(\"maximum length of Hindi Sentence \",max(lines['length_hin_sentence']))\nprint(\"maximum length of English Sentence \",max(lines['length_eng_sentence']))","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:33:43.700362Z","iopub.execute_input":"2024-06-27T09:33:43.700646Z","iopub.status.idle":"2024-06-27T09:33:43.707638Z","shell.execute_reply.started":"2024-06-27T09:33:43.700606Z","shell.execute_reply":"2024-06-27T09:33:43.706772Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"maximum length of Hindi Sentence  20\nmaximum length of English Sentence  20\n","output_type":"stream"}]},{"cell_type":"code","source":"max_length_src=max(lines['length_hin_sentence'])\nmax_length_tar=max(lines['length_eng_sentence'])","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:33:44.633151Z","iopub.execute_input":"2024-06-27T09:33:44.633430Z","iopub.status.idle":"2024-06-27T09:33:44.639839Z","shell.execute_reply.started":"2024-06-27T09:33:44.633390Z","shell.execute_reply":"2024-06-27T09:33:44.638836Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"input_words = sorted(list(all_eng_words))\ntarget_words = sorted(list(all_hindi_words))\nnum_encoder_tokens = len(all_eng_words)\nnum_decoder_tokens = len(all_hindi_words)\nnum_encoder_tokens, num_decoder_tokens","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:33:45.415043Z","iopub.execute_input":"2024-06-27T09:33:45.415373Z","iopub.status.idle":"2024-06-27T09:33:45.438104Z","shell.execute_reply.started":"2024-06-27T09:33:45.415312Z","shell.execute_reply":"2024-06-27T09:33:45.437260Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"(14030, 17540)"},"metadata":{}}]},{"cell_type":"code","source":"num_decoder_tokens += 1 #for zero padding\n","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:33:46.250279Z","iopub.execute_input":"2024-06-27T09:33:46.250590Z","iopub.status.idle":"2024-06-27T09:33:46.254105Z","shell.execute_reply.started":"2024-06-27T09:33:46.250534Z","shell.execute_reply":"2024-06-27T09:33:46.253214Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\ntarget_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:33:46.712335Z","iopub.execute_input":"2024-06-27T09:33:46.712611Z","iopub.status.idle":"2024-06-27T09:33:46.732201Z","shell.execute_reply.started":"2024-06-27T09:33:46.712563Z","shell.execute_reply":"2024-06-27T09:33:46.731461Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\nreverse_target_char_index = dict((i, word) for word, i in target_token_index.items())","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:33:47.841748Z","iopub.execute_input":"2024-06-27T09:33:47.842084Z","iopub.status.idle":"2024-06-27T09:33:47.854247Z","shell.execute_reply.started":"2024-06-27T09:33:47.842024Z","shell.execute_reply":"2024-06-27T09:33:47.853401Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"lines = shuffle(lines)\nlines.head(10)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:33:49.073900Z","iopub.execute_input":"2024-06-27T09:33:49.074226Z","iopub.status.idle":"2024-06-27T09:33:49.093415Z","shell.execute_reply.started":"2024-06-27T09:33:49.074181Z","shell.execute_reply":"2024-06-27T09:33:49.092658Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"       source                                                                  english_sentence                                                                            hindi_sentence  length_eng_sentence  length_hin_sentence\n18072   ted    especially when the people cant pay for it                                        START_ ख़ासतौर पर तब जब कि लोग पैसे देने में सक्षम हैं ही नहीं _END                       8                    15                 \n34880   ted    so thats what t is doing                                                          START_ और ठीक यही टी कर रहा है _END                                                       6                    9                  \n78273   ted    any one of you could be famous on the internet                                    START_ और कोई भी इंटरनेट पर अगले शनिवार तक _END                                           10                   10                 \n117038  ted    seen and heard different versions                                                 START_ ऐसी ही एकतरफा कहानी के विभिन्न _END                                                5                    8                  \n19890   ted    theyre prophecy                                                                   START_ वे भविष्यवाणी हैं _END                                                             2                    5                  \n100770  ted    and i think that this will be one of the more important companies in east africa  START_ और मुझे लगता है कि ये पूर्वी अफ़्रीका की महत्वपूर्ण कंपनियों में से एक होगी। _END  16                   17                 \n23151   ted    so it was like about a half an hour for a lightning call to come through          START_ उस लाइटनिंग काल के लिए भी हमे आधा घंटा इंतज़ार करना पड़ता था _END                  16                   15                 \n68140   ted    and it will make very highresolution maps                                         START_ जो बहुत अधिक रिज़ोल्यूशन के मानचित्र उपलब्ध कराएगा _END                            7                    10                 \n96287   ted    so whats a technology that will allow us                                          START_ तो क्या है वेह तकनीक जो कि हमें असाधारण _END                                       8                    11                 \n6541    ted    you think that its not true of course                                             START_ आप ये सोच तै है मगर ये सच नहीं है _END                                             8                    12                 ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>english_sentence</th>\n      <th>hindi_sentence</th>\n      <th>length_eng_sentence</th>\n      <th>length_hin_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>18072</th>\n      <td>ted</td>\n      <td>especially when the people cant pay for it</td>\n      <td>START_ ख़ासतौर पर तब जब कि लोग पैसे देने में सक्षम हैं ही नहीं _END</td>\n      <td>8</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>34880</th>\n      <td>ted</td>\n      <td>so thats what t is doing</td>\n      <td>START_ और ठीक यही टी कर रहा है _END</td>\n      <td>6</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>78273</th>\n      <td>ted</td>\n      <td>any one of you could be famous on the internet</td>\n      <td>START_ और कोई भी इंटरनेट पर अगले शनिवार तक _END</td>\n      <td>10</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>117038</th>\n      <td>ted</td>\n      <td>seen and heard different versions</td>\n      <td>START_ ऐसी ही एकतरफा कहानी के विभिन्न _END</td>\n      <td>5</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>19890</th>\n      <td>ted</td>\n      <td>theyre prophecy</td>\n      <td>START_ वे भविष्यवाणी हैं _END</td>\n      <td>2</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>100770</th>\n      <td>ted</td>\n      <td>and i think that this will be one of the more important companies in east africa</td>\n      <td>START_ और मुझे लगता है कि ये पूर्वी अफ़्रीका की महत्वपूर्ण कंपनियों में से एक होगी। _END</td>\n      <td>16</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>23151</th>\n      <td>ted</td>\n      <td>so it was like about a half an hour for a lightning call to come through</td>\n      <td>START_ उस लाइटनिंग काल के लिए भी हमे आधा घंटा इंतज़ार करना पड़ता था _END</td>\n      <td>16</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>68140</th>\n      <td>ted</td>\n      <td>and it will make very highresolution maps</td>\n      <td>START_ जो बहुत अधिक रिज़ोल्यूशन के मानचित्र उपलब्ध कराएगा _END</td>\n      <td>7</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>96287</th>\n      <td>ted</td>\n      <td>so whats a technology that will allow us</td>\n      <td>START_ तो क्या है वेह तकनीक जो कि हमें असाधारण _END</td>\n      <td>8</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>6541</th>\n      <td>ted</td>\n      <td>you think that its not true of course</td>\n      <td>START_ आप ये सोच तै है मगर ये सच नहीं है _END</td>\n      <td>8</td>\n      <td>12</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Split the data into train and test","metadata":{}},{"cell_type":"code","source":"X, y = lines['english_sentence'], lines['hindi_sentence']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=42)\nX_train.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:33:56.142251Z","iopub.execute_input":"2024-06-27T09:33:56.142559Z","iopub.status.idle":"2024-06-27T09:33:56.156617Z","shell.execute_reply.started":"2024-06-27T09:33:56.142514Z","shell.execute_reply":"2024-06-27T09:33:56.155657Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"((19819,), (4955,))"},"metadata":{}}]},{"cell_type":"markdown","source":"### Let us save this data","metadata":{}},{"cell_type":"code","source":"X_train.to_pickle('X_train.pkl')\nX_test.to_pickle('X_test.pkl')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:33:59.996820Z","iopub.execute_input":"2024-06-27T09:33:59.997124Z","iopub.status.idle":"2024-06-27T09:34:00.271130Z","shell.execute_reply.started":"2024-06-27T09:33:59.997081Z","shell.execute_reply":"2024-06-27T09:34:00.270500Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"def generate_batch(X = X_train, y = y_train, batch_size = 128):\n    ''' Generate a batch of data '''\n    while True:\n        for j in range(0, len(X), batch_size):\n            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n                for t, word in enumerate(input_text.split()):\n                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n                for t, word in enumerate(target_text.split()):\n                    if t<len(target_text.split())-1:\n                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n                    if t>0:\n                        # decoder target sequence (one hot encoded)\n                        # does not include the START_ token\n                        # Offset by one timestep\n                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n            yield([encoder_input_data, decoder_input_data], decoder_target_data)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:34:04.076401Z","iopub.execute_input":"2024-06-27T09:34:04.076680Z","iopub.status.idle":"2024-06-27T09:34:04.085215Z","shell.execute_reply.started":"2024-06-27T09:34:04.076640Z","shell.execute_reply":"2024-06-27T09:34:04.084267Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"### Encoder-Decoder Architecture","metadata":{}},{"cell_type":"code","source":"latent_dim=300","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:34:08.767667Z","iopub.execute_input":"2024-06-27T09:34:08.767943Z","iopub.status.idle":"2024-06-27T09:34:08.771604Z","shell.execute_reply.started":"2024-06-27T09:34:08.767902Z","shell.execute_reply":"2024-06-27T09:34:08.770746Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# Encoder\nencoder_inputs = Input(shape=(None,))\nenc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\nencoder_lstm = LSTM(latent_dim, return_state=True)\nencoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n# We discard `encoder_outputs` and only keep the states.\nencoder_states = [state_h, state_c]","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:34:10.388040Z","iopub.execute_input":"2024-06-27T09:34:10.388322Z","iopub.status.idle":"2024-06-27T09:34:10.839359Z","shell.execute_reply.started":"2024-06-27T09:34:10.388281Z","shell.execute_reply":"2024-06-27T09:34:10.838760Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set up the decoder, using `encoder_states` as initial state.\ndecoder_inputs = Input(shape=(None,))\ndec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\ndec_emb = dec_emb_layer(decoder_inputs)\n# We set up our decoder to return full output sequences,\n# and to return internal states as well. We don't use the\n# return states in the training model, but we will use them in inference.\ndecoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\ndecoder_outputs, _, _ = decoder_lstm(dec_emb,\n                                     initial_state=encoder_states)\ndecoder_dense = Dense(num_decoder_tokens, activation='softmax')\ndecoder_outputs = decoder_dense(decoder_outputs)\n\n# Define the model that will turn\n# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\nmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:34:12.324638Z","iopub.execute_input":"2024-06-27T09:34:12.324923Z","iopub.status.idle":"2024-06-27T09:34:12.745645Z","shell.execute_reply.started":"2024-06-27T09:34:12.324880Z","shell.execute_reply":"2024-06-27T09:34:12.744918Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='rmsprop', loss='categorical_crossentropy')","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:34:18.405820Z","iopub.execute_input":"2024-06-27T09:34:18.406156Z","iopub.status.idle":"2024-06-27T09:34:18.445384Z","shell.execute_reply.started":"2024-06-27T09:34:18.406104Z","shell.execute_reply":"2024-06-27T09:34:18.444795Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:34:19.309565Z","iopub.execute_input":"2024-06-27T09:34:19.309869Z","iopub.status.idle":"2024-06-27T09:34:19.316721Z","shell.execute_reply.started":"2024-06-27T09:34:19.309823Z","shell.execute_reply":"2024-06-27T09:34:19.315341Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, None)         0                                            \n__________________________________________________________________________________________________\ninput_2 (InputLayer)            (None, None)         0                                            \n__________________________________________________________________________________________________\nembedding_1 (Embedding)         (None, None, 300)    4209000     input_1[0][0]                    \n__________________________________________________________________________________________________\nembedding_2 (Embedding)         (None, None, 300)    5262300     input_2[0][0]                    \n__________________________________________________________________________________________________\nlstm_1 (LSTM)                   [(None, 300), (None, 721200      embedding_1[0][0]                \n__________________________________________________________________________________________________\nlstm_2 (LSTM)                   [(None, None, 300),  721200      embedding_2[0][0]                \n                                                                 lstm_1[0][1]                     \n                                                                 lstm_1[0][2]                     \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, None, 17541)  5279841     lstm_2[0][0]                     \n==================================================================================================\nTotal params: 16,193,541\nTrainable params: 16,193,541\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"train_samples = len(X_train)\nval_samples = len(X_test)\nbatch_size = 128\nepochs = 100","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:34:22.775539Z","iopub.execute_input":"2024-06-27T09:34:22.775832Z","iopub.status.idle":"2024-06-27T09:34:22.779775Z","shell.execute_reply.started":"2024-06-27T09:34:22.775790Z","shell.execute_reply":"2024-06-27T09:34:22.779103Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n                    steps_per_epoch = train_samples//batch_size,\n                    epochs=epochs,\n                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n                    validation_steps = val_samples//batch_size)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-27T05:12:07.611620Z","iopub.execute_input":"2024-06-27T05:12:07.611909Z","iopub.status.idle":"2024-06-27T06:54:56.783268Z","shell.execute_reply.started":"2024-06-27T05:12:07.611854Z","shell.execute_reply":"2024-06-27T06:54:56.782454Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nDeprecated in favor of operator or tf.math.divide.\nEpoch 1/100\n154/154 [==============================] - 66s 429ms/step - loss: 6.4294 - val_loss: 6.1722\nEpoch 2/100\n154/154 [==============================] - 62s 401ms/step - loss: 5.8424 - val_loss: 5.8525\nEpoch 3/100\n154/154 [==============================] - 62s 400ms/step - loss: 5.4780 - val_loss: 5.6188\nEpoch 4/100\n154/154 [==============================] - 61s 398ms/step - loss: 5.2291 - val_loss: 5.5164\nEpoch 5/100\n154/154 [==============================] - 61s 398ms/step - loss: 5.0163 - val_loss: 5.4669\nEpoch 6/100\n154/154 [==============================] - 61s 398ms/step - loss: 4.8324 - val_loss: 5.3945\nEpoch 7/100\n154/154 [==============================] - 62s 400ms/step - loss: 4.6594 - val_loss: 5.3427\nEpoch 8/100\n154/154 [==============================] - 62s 401ms/step - loss: 4.4980 - val_loss: 5.3331\nEpoch 9/100\n154/154 [==============================] - 61s 399ms/step - loss: 4.3456 - val_loss: 5.3025\nEpoch 10/100\n154/154 [==============================] - 62s 399ms/step - loss: 4.1975 - val_loss: 5.2846\nEpoch 11/100\n154/154 [==============================] - 61s 398ms/step - loss: 4.0534 - val_loss: 5.2703\nEpoch 12/100\n154/154 [==============================] - 62s 400ms/step - loss: 3.9141 - val_loss: 5.2933\nEpoch 13/100\n154/154 [==============================] - 62s 399ms/step - loss: 3.7793 - val_loss: 5.3041\nEpoch 14/100\n154/154 [==============================] - 62s 400ms/step - loss: 3.6474 - val_loss: 5.3157\nEpoch 15/100\n154/154 [==============================] - 62s 400ms/step - loss: 3.5194 - val_loss: 5.3347\nEpoch 16/100\n154/154 [==============================] - 62s 401ms/step - loss: 3.3932 - val_loss: 5.3606\nEpoch 17/100\n154/154 [==============================] - 62s 400ms/step - loss: 3.2715 - val_loss: 5.3978\nEpoch 18/100\n154/154 [==============================] - 62s 401ms/step - loss: 3.1523 - val_loss: 5.4164\nEpoch 19/100\n154/154 [==============================] - 62s 400ms/step - loss: 3.0366 - val_loss: 5.4477\nEpoch 20/100\n154/154 [==============================] - 62s 401ms/step - loss: 2.9201 - val_loss: 5.5070\nEpoch 21/100\n154/154 [==============================] - 62s 400ms/step - loss: 2.8095 - val_loss: 5.5348\nEpoch 22/100\n154/154 [==============================] - 62s 401ms/step - loss: 2.7029 - val_loss: 5.5670\nEpoch 23/100\n154/154 [==============================] - 63s 406ms/step - loss: 2.5980 - val_loss: 5.6238\nEpoch 24/100\n154/154 [==============================] - 63s 408ms/step - loss: 2.4919 - val_loss: 5.6751\nEpoch 25/100\n154/154 [==============================] - 62s 402ms/step - loss: 2.3876 - val_loss: 5.7300\nEpoch 26/100\n154/154 [==============================] - 62s 402ms/step - loss: 2.2871 - val_loss: 5.7790\nEpoch 27/100\n154/154 [==============================] - 62s 401ms/step - loss: 2.1889 - val_loss: 5.8083\nEpoch 28/100\n154/154 [==============================] - 62s 400ms/step - loss: 2.0938 - val_loss: 5.8486\nEpoch 29/100\n154/154 [==============================] - 62s 399ms/step - loss: 1.9984 - val_loss: 5.8927\nEpoch 30/100\n154/154 [==============================] - 62s 400ms/step - loss: 1.9112 - val_loss: 5.9429\nEpoch 31/100\n154/154 [==============================] - 62s 400ms/step - loss: 1.8231 - val_loss: 5.9844\nEpoch 32/100\n154/154 [==============================] - 62s 400ms/step - loss: 1.7415 - val_loss: 6.0449\nEpoch 33/100\n154/154 [==============================] - 62s 400ms/step - loss: 1.6614 - val_loss: 6.0953\nEpoch 34/100\n154/154 [==============================] - 62s 399ms/step - loss: 1.5865 - val_loss: 6.1552\nEpoch 35/100\n154/154 [==============================] - 62s 401ms/step - loss: 1.5133 - val_loss: 6.1993\nEpoch 36/100\n154/154 [==============================] - 62s 400ms/step - loss: 1.4442 - val_loss: 6.2470\nEpoch 37/100\n154/154 [==============================] - 62s 401ms/step - loss: 1.3760 - val_loss: 6.2910\nEpoch 38/100\n154/154 [==============================] - 62s 402ms/step - loss: 1.3118 - val_loss: 6.3382\nEpoch 39/100\n154/154 [==============================] - 62s 400ms/step - loss: 1.2487 - val_loss: 6.3834\nEpoch 40/100\n154/154 [==============================] - 62s 400ms/step - loss: 1.1901 - val_loss: 6.4312\nEpoch 41/100\n154/154 [==============================] - 62s 401ms/step - loss: 1.1374 - val_loss: 6.4688\nEpoch 42/100\n154/154 [==============================] - 62s 400ms/step - loss: 1.0818 - val_loss: 6.5200\nEpoch 43/100\n154/154 [==============================] - 62s 402ms/step - loss: 1.0334 - val_loss: 6.5596\nEpoch 44/100\n154/154 [==============================] - 62s 401ms/step - loss: 0.9873 - val_loss: 6.5845\nEpoch 45/100\n154/154 [==============================] - 62s 401ms/step - loss: 0.9416 - val_loss: 6.6172\nEpoch 46/100\n154/154 [==============================] - 62s 401ms/step - loss: 0.8976 - val_loss: 6.6474\nEpoch 47/100\n154/154 [==============================] - 62s 401ms/step - loss: 0.8579 - val_loss: 6.6915\nEpoch 48/100\n154/154 [==============================] - 62s 402ms/step - loss: 0.8172 - val_loss: 6.7376\nEpoch 49/100\n154/154 [==============================] - 62s 400ms/step - loss: 0.7780 - val_loss: 6.7827\nEpoch 50/100\n154/154 [==============================] - 62s 402ms/step - loss: 0.7398 - val_loss: 6.8100\nEpoch 51/100\n154/154 [==============================] - 62s 401ms/step - loss: 0.7047 - val_loss: 6.8450\nEpoch 52/100\n154/154 [==============================] - 62s 401ms/step - loss: 0.6746 - val_loss: 6.8907\nEpoch 53/100\n154/154 [==============================] - 62s 403ms/step - loss: 0.6425 - val_loss: 6.9130\nEpoch 54/100\n154/154 [==============================] - 62s 403ms/step - loss: 0.6106 - val_loss: 6.9485\nEpoch 55/100\n154/154 [==============================] - 62s 404ms/step - loss: 0.5859 - val_loss: 6.9608\nEpoch 56/100\n154/154 [==============================] - 62s 402ms/step - loss: 0.5579 - val_loss: 6.9973\nEpoch 57/100\n154/154 [==============================] - 62s 402ms/step - loss: 0.5337 - val_loss: 7.0205\nEpoch 58/100\n154/154 [==============================] - 62s 403ms/step - loss: 0.5057 - val_loss: 7.0396\nEpoch 59/100\n154/154 [==============================] - 62s 402ms/step - loss: 0.4815 - val_loss: 7.0862\nEpoch 60/100\n154/154 [==============================] - 62s 401ms/step - loss: 0.4583 - val_loss: 7.0846\nEpoch 61/100\n154/154 [==============================] - 62s 401ms/step - loss: 0.4391 - val_loss: 7.1241\nEpoch 62/100\n154/154 [==============================] - 62s 401ms/step - loss: 0.4202 - val_loss: 7.1563\nEpoch 63/100\n154/154 [==============================] - 62s 400ms/step - loss: 0.4019 - val_loss: 7.1879\nEpoch 64/100\n154/154 [==============================] - 62s 400ms/step - loss: 0.3830 - val_loss: 7.2096\nEpoch 65/100\n154/154 [==============================] - 61s 399ms/step - loss: 0.3674 - val_loss: 7.2317\nEpoch 66/100\n154/154 [==============================] - 62s 400ms/step - loss: 0.3530 - val_loss: 7.2533\nEpoch 67/100\n154/154 [==============================] - 62s 400ms/step - loss: 0.3396 - val_loss: 7.2704\nEpoch 68/100\n154/154 [==============================] - 62s 401ms/step - loss: 0.3266 - val_loss: 7.2897\nEpoch 69/100\n154/154 [==============================] - 62s 400ms/step - loss: 0.3120 - val_loss: 7.2997\nEpoch 70/100\n154/154 [==============================] - 62s 401ms/step - loss: 0.2981 - val_loss: 7.3283\nEpoch 71/100\n154/154 [==============================] - 62s 400ms/step - loss: 0.2877 - val_loss: 7.3394\nEpoch 72/100\n154/154 [==============================] - 62s 402ms/step - loss: 0.2751 - val_loss: 7.3452\nEpoch 73/100\n154/154 [==============================] - 62s 400ms/step - loss: 0.2641 - val_loss: 7.3700\nEpoch 74/100\n154/154 [==============================] - 62s 400ms/step - loss: 0.2525 - val_loss: 7.3957\nEpoch 75/100\n154/154 [==============================] - 62s 403ms/step - loss: 0.2445 - val_loss: 7.3954\nEpoch 76/100\n154/154 [==============================] - 62s 401ms/step - loss: 0.2336 - val_loss: 7.4201\nEpoch 77/100\n154/154 [==============================] - 62s 400ms/step - loss: 0.2230 - val_loss: 7.4202\nEpoch 78/100\n154/154 [==============================] - 62s 402ms/step - loss: 0.2146 - val_loss: 7.4323\nEpoch 79/100\n154/154 [==============================] - 62s 400ms/step - loss: 0.2077 - val_loss: 7.4443\nEpoch 80/100\n154/154 [==============================] - 61s 399ms/step - loss: 0.1971 - val_loss: 7.4639\nEpoch 81/100\n154/154 [==============================] - 61s 398ms/step - loss: 0.1898 - val_loss: 7.4957\nEpoch 82/100\n154/154 [==============================] - 61s 398ms/step - loss: 0.1833 - val_loss: 7.5112\nEpoch 83/100\n154/154 [==============================] - 61s 398ms/step - loss: 0.1768 - val_loss: 7.5284\nEpoch 84/100\n154/154 [==============================] - 61s 398ms/step - loss: 0.1706 - val_loss: 7.5187\nEpoch 85/100\n154/154 [==============================] - 61s 398ms/step - loss: 0.1635 - val_loss: 7.5303\nEpoch 86/100\n154/154 [==============================] - 61s 397ms/step - loss: 0.1556 - val_loss: 7.5575\nEpoch 87/100\n154/154 [==============================] - 61s 399ms/step - loss: 0.1500 - val_loss: 7.5766\nEpoch 88/100\n154/154 [==============================] - 61s 399ms/step - loss: 0.1451 - val_loss: 7.5821\nEpoch 89/100\n154/154 [==============================] - 61s 397ms/step - loss: 0.1387 - val_loss: 7.5768\nEpoch 90/100\n154/154 [==============================] - 61s 396ms/step - loss: 0.1344 - val_loss: 7.5968\nEpoch 91/100\n154/154 [==============================] - 61s 399ms/step - loss: 0.1286 - val_loss: 7.6075\nEpoch 92/100\n154/154 [==============================] - 61s 397ms/step - loss: 0.1222 - val_loss: 7.6255\nEpoch 93/100\n154/154 [==============================] - 61s 398ms/step - loss: 0.1183 - val_loss: 7.6464\nEpoch 94/100\n154/154 [==============================] - 61s 397ms/step - loss: 0.1133 - val_loss: 7.6454\nEpoch 95/100\n154/154 [==============================] - 61s 399ms/step - loss: 0.1089 - val_loss: 7.6613\nEpoch 96/100\n154/154 [==============================] - 61s 397ms/step - loss: 0.1054 - val_loss: 7.6546\nEpoch 97/100\n154/154 [==============================] - 61s 398ms/step - loss: 0.1019 - val_loss: 7.6791\nEpoch 98/100\n154/154 [==============================] - 61s 397ms/step - loss: 0.0974 - val_loss: 7.7092\nEpoch 99/100\n154/154 [==============================] - 61s 399ms/step - loss: 0.0936 - val_loss: 7.6935\nEpoch 100/100\n154/154 [==============================] - 61s 398ms/step - loss: 0.0903 - val_loss: 7.7228\n","output_type":"stream"},{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7ff30f20fb38>"},"metadata":{}}]},{"cell_type":"code","source":"model.save_weights('nmt_weights.h5')","metadata":{"execution":{"iopub.status.busy":"2024-06-27T06:54:56.788024Z","iopub.execute_input":"2024-06-27T06:54:56.788388Z","iopub.status.idle":"2024-06-27T06:54:57.047598Z","shell.execute_reply.started":"2024-06-27T06:54:56.788319Z","shell.execute_reply":"2024-06-27T06:54:57.046849Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"# Encode the input sequence to get the \"thought vectors\"\nencoder_model = Model(encoder_inputs, encoder_states)\n\n# Decoder setup\n# Below tensors will hold the states of the previous time step\ndecoder_state_input_h = Input(shape=(latent_dim,))\ndecoder_state_input_c = Input(shape=(latent_dim,))\ndecoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n\ndec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n\n# To predict the next word in the sequence, set the initial states to the states from the previous time step\ndecoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\ndecoder_states2 = [state_h2, state_c2]\ndecoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n\n# Final decoder model\ndecoder_model = Model(\n    [decoder_inputs] + decoder_states_inputs,\n    [decoder_outputs2] + decoder_states2)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:34:34.175384Z","iopub.execute_input":"2024-06-27T09:34:34.175667Z","iopub.status.idle":"2024-06-27T09:34:34.355557Z","shell.execute_reply.started":"2024-06-27T09:34:34.175625Z","shell.execute_reply":"2024-06-27T09:34:34.354962Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"def decode_sequence(input_seq):\n    # Encode the input as state vectors.\n    states_value = encoder_model.predict(input_seq)\n    # Generate empty target sequence of length 1.\n    target_seq = np.zeros((1,1))\n    # Populate the first character of target sequence with the start character.\n    target_seq[0, 0] = target_token_index['START_']\n\n    # Sampling loop for a batch of sequences\n    # (to simplify, here we assume a batch of size 1).\n    stop_condition = False\n    decoded_sentence = ''\n    while not stop_condition:\n        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n\n        # Sample a token\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_char = reverse_target_char_index[sampled_token_index]\n        decoded_sentence += ' '+sampled_char\n\n        # Exit condition: either hit max length\n        # or find stop character.\n        if (sampled_char == '_END' or\n           len(decoded_sentence) > 50):\n            stop_condition = True\n\n        # Update the target sequence (of length 1).\n        target_seq = np.zeros((1,1))\n        target_seq[0, 0] = sampled_token_index\n\n        # Update states\n        states_value = [h, c]\n\n    return decoded_sentence","metadata":{"execution":{"iopub.status.busy":"2024-06-27T09:34:38.298348Z","iopub.execute_input":"2024-06-27T09:34:38.298629Z","iopub.status.idle":"2024-06-27T09:34:38.306681Z","shell.execute_reply.started":"2024-06-27T09:34:38.298587Z","shell.execute_reply":"2024-06-27T09:34:38.305897Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"train_gen = generate_batch(X_train, y_train, batch_size = 1)\nk=-1\n","metadata":{"execution":{"iopub.status.busy":"2024-06-27T06:54:57.238547Z","iopub.execute_input":"2024-06-27T06:54:57.238892Z","iopub.status.idle":"2024-06-27T06:54:57.249654Z","shell.execute_reply.started":"2024-06-27T06:54:57.238777Z","shell.execute_reply":"2024-06-27T06:54:57.248893Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"k+=1\n(input_seq, actual_output), _ = next(train_gen)\ndecoded_sentence = decode_sequence(input_seq)\nprint('Input English sentence:', X_train[k:k+1].values[0])\nprint('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\nprint('Predicted Hindi Translation:', decoded_sentence[:-4])","metadata":{"execution":{"iopub.status.busy":"2024-06-27T06:54:57.250664Z","iopub.execute_input":"2024-06-27T06:54:57.250890Z","iopub.status.idle":"2024-06-27T06:54:57.603637Z","shell.execute_reply.started":"2024-06-27T06:54:57.250847Z","shell.execute_reply":"2024-06-27T06:54:57.602759Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"Input English sentence: had used her brutally\nActual Hindi Translation:  उसका निर्दयता से उपभोग किया था \nPredicted Hindi Translation:  उसका निर्दयता से उपभोग किया था \n","output_type":"stream"}]},{"cell_type":"code","source":"k+=1\n(input_seq, actual_output), _ = next(train_gen)\ndecoded_sentence = decode_sequence(input_seq)\nprint('Input English sentence:', X_train[k:k+1].values[0])\nprint('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\nprint('Predicted Hindi Translation:', decoded_sentence[:-4])","metadata":{"execution":{"iopub.status.busy":"2024-06-27T06:54:57.604698Z","iopub.execute_input":"2024-06-27T06:54:57.604909Z","iopub.status.idle":"2024-06-27T06:54:57.639092Z","shell.execute_reply.started":"2024-06-27T06:54:57.604871Z","shell.execute_reply":"2024-06-27T06:54:57.638405Z"},"trusted":true},"execution_count":85,"outputs":[{"name":"stdout","text":"Input English sentence: in fact legend has is that when doubting thomas the apostle saint thomas\nActual Hindi Translation:  यहाँ तक की यह भी कहा जाता है की देवदूत के शक करने पर संत थोमस \nPredicted Hindi Translation:  यहाँ भी यह कहा की है कि सामाजिक शक्ति से रहा ह\n","output_type":"stream"}]},{"cell_type":"code","source":"k+=1\n(input_seq, actual_output), _ = next(train_gen)\ndecoded_sentence = decode_sequence(input_seq)\nprint('Input English sentence:', X_train[k:k+1].values[0])\nprint('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\nprint('Predicted Hindi Translation:', decoded_sentence[:-4])","metadata":{"execution":{"iopub.status.busy":"2024-06-27T06:54:57.640205Z","iopub.execute_input":"2024-06-27T06:54:57.640451Z","iopub.status.idle":"2024-06-27T06:54:57.668945Z","shell.execute_reply.started":"2024-06-27T06:54:57.640411Z","shell.execute_reply":"2024-06-27T06:54:57.668302Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stdout","text":"Input English sentence: that i could actually get a fractional percent of a cent\nActual Hindi Translation:  मुझे एक पैसे का केवल कुछ भाग ही मिलेगा \nPredicted Hindi Translation:  मुझे एक पैसे का अवसर का एक जरुरत है \n","output_type":"stream"}]},{"cell_type":"code","source":"k+=1\n(input_seq, actual_output), _ = next(train_gen)\ndecoded_sentence = decode_sequence(input_seq)\nprint('Input English sentence:', X_train[k:k+1].values[0])\nprint('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\nprint('Predicted Hindi Translation:', decoded_sentence[:-4])","metadata":{"execution":{"iopub.status.busy":"2024-06-27T06:54:57.669891Z","iopub.execute_input":"2024-06-27T06:54:57.670098Z","iopub.status.idle":"2024-06-27T06:54:57.721174Z","shell.execute_reply.started":"2024-06-27T06:54:57.670054Z","shell.execute_reply":"2024-06-27T06:54:57.720313Z"},"trusted":true},"execution_count":87,"outputs":[{"name":"stdout","text":"Input English sentence: the bad news is they were all photocopies so we didnt make a dime in revenue\nActual Hindi Translation:  बुरी खबर ये है कि ये सब फ़ोटोकापियाँ थी तो हमने इस से एक भी पैसा नहीं कमाया। \nPredicted Hindi Translation:  बुरी खबर ये है कि हम किसी बात पर विश्वास नहीं घ\n","output_type":"stream"}]},{"cell_type":"code","source":"k+=1\n(input_seq, actual_output), _ = next(train_gen)\ndecoded_sentence = decode_sequence(input_seq)\nprint('Input English sentence:', X_train[k:k+1].values[0])\nprint('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\nprint('Predicted Hindi Translation:', decoded_sentence[:-4])","metadata":{"execution":{"iopub.status.busy":"2024-06-27T06:54:57.723119Z","iopub.execute_input":"2024-06-27T06:54:57.723723Z","iopub.status.idle":"2024-06-27T06:54:57.764486Z","shell.execute_reply.started":"2024-06-27T06:54:57.723666Z","shell.execute_reply":"2024-06-27T06:54:57.763599Z"},"trusted":true},"execution_count":88,"outputs":[{"name":"stdout","text":"Input English sentence: that these kids would have been trained to see as “disabled”\nActual Hindi Translation:  जिसे ये बच्चे “विकलांग” या “अक्षम” समझने के आदी होते \nPredicted Hindi Translation:  जिसे यह बच्चों को जन्म है जिसे आपके पास तमाम ह\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Encoder Decoder with attention","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Bidirectional, Concatenate\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom sklearn.model_selection import train_test_split\n\n# Assuming you have loaded and preprocessed your data into X_train, X_test, y_train, y_test\n# and have dictionaries input_token_index and target_token_index\n\n# Parameters\nbatch_size = 128\nepochs = 50\nlatent_dim = 300  # Dimensionality of the encoding space\n\n# Encoder input\nencoder_inputs = Input(shape=(None,))\nenc_emb = Embedding(num_encoder_tokens, latent_dim, mask_zero=True)(encoder_inputs)\nencoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\nencoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\nencoder_states = [state_h, state_c]\n\n# Decoder input\ndecoder_inputs = Input(shape=(None,))\ndec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero=True)\ndec_emb = dec_emb_layer(decoder_inputs)\ndecoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\ndecoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n\n# Custom attention mechanism\ndef attention(inputs):\n    encoder_outputs, decoder_outputs = inputs\n    # Score calculation\n    score = tf.matmul(decoder_outputs, encoder_outputs, transpose_b=True)\n    attention_weights = tf.nn.softmax(score, axis=-1)\n    # Context vector calculation\n    context_vector = tf.matmul(attention_weights, encoder_outputs)\n    return context_vector\n\n# Applying attention mechanism\nattn_output = attention([encoder_outputs, decoder_outputs])\n# Concatenate attention output and decoder LSTM output\ndecoder_concat_input = Concatenate(axis=-1)([decoder_outputs, attn_output])\n\n# Dense layer\ndecoder_dense = Dense(num_decoder_tokens, activation='softmax')\ndecoder_outputs = decoder_dense(decoder_concat_input)\n\n# Define the model\nmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Print model summary\nprint(model.summary())\n\n# Train the model\ntrain_samples = len(X_train)\nval_samples = len(X_test)\nsteps_per_epoch = train_samples // batch_size\nval_steps = val_samples // batch_size\n\ncheckpoint = ModelCheckpoint('best_model.h5', save_best_only=True)\n\n# Train the model\nmodel.fit(generate_batch(X_train, y_train, batch_size=batch_size),\n          steps_per_epoch=steps_per_epoch,\n          epochs=epochs,\n          validation_data=generate_batch(X_test, y_test, batch_size=batch_size),\n          validation_steps=val_steps,\n          callbacks=[checkpoint])\n\n# Save the model\nmodel.save('s2s_attention_custom.h5')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 128\nepochs = 50\nlatent_dim = 300","metadata":{"execution":{"iopub.status.busy":"2024-06-27T06:54:57.779988Z","iopub.execute_input":"2024-06-27T06:54:57.780194Z","iopub.status.idle":"2024-06-27T06:54:57.789421Z","shell.execute_reply.started":"2024-06-27T06:54:57.780159Z","shell.execute_reply":"2024-06-27T06:54:57.788621Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T06:54:57.800645Z","iopub.execute_input":"2024-06-27T06:54:57.800894Z","iopub.status.idle":"2024-06-27T06:54:58.077447Z","shell.execute_reply.started":"2024-06-27T06:54:57.800854Z","shell.execute_reply":"2024-06-27T06:54:58.076842Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"def attention(inputs):\n    encoder_outputs, decoder_outputs = inputs\n    # score shape == (batch_size, max_length, 1)\n    score = tf.matmul(decoder_outputs, encoder_outputs, transpose_b=True)\n    # attention_weights shape == (batch_size, max_length, 1)\n    attention_weights = tf.nn.softmax(score, axis=2)\n    # context_vector shape after sum == (batch_size, hidden_size)\n    context_vector = tf.matmul(attention_weights, encoder_outputs)\n    return context_vector","metadata":{"execution":{"iopub.status.busy":"2024-06-27T06:54:57.790429Z","iopub.execute_input":"2024-06-27T06:54:57.790631Z","iopub.status.idle":"2024-06-27T06:54:57.799567Z","shell.execute_reply.started":"2024-06-27T06:54:57.790596Z","shell.execute_reply":"2024-06-27T06:54:57.798883Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nattn_output = attention([encoder_outputs, decoder_outputs])\n# Concatenate attention output and decoder LSTM output\ndecoder_concat_input = Concatenate(axis=-1)([decoder_outputs, attn_output])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"decoder_dense = Dense(num_decoder_tokens, activation='softmax')\ndecoder_outputs = decoder_dense(decoder_concat_input)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T06:54:58.108781Z","iopub.status.idle":"2024-06-27T06:54:58.109247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nprint(model.summary())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_samples = len(X_train)\nval_samples = len(X_test)\nsteps_per_epoch = train_samples \nval_steps = val_samples ","metadata":{"execution":{"iopub.status.busy":"2024-06-27T06:54:58.110209Z","iopub.status.idle":"2024-06-27T06:54:58.110795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = ModelCheckpoint('attention_lstm.h5', save_best_only=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-27T06:54:58.111693Z","iopub.status.idle":"2024-06-27T06:54:58.112381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(generate_batch(X_train, y_train, batch_size=batch_size),\n          steps_per_epoch=steps_per_epoch,\n          epochs=epochs,\n          validation_data=generate_batch(X_test, y_test, batch_size=batch_size),\n          validation_steps=val_steps,\n          callbacks=[checkpoint])","metadata":{"execution":{"iopub.status.busy":"2024-06-27T06:54:58.113197Z","iopub.status.idle":"2024-06-27T06:54:58.113936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('attention_custom.h5')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-27T06:54:58.114738Z","iopub.status.idle":"2024-06-27T06:54:58.115438Z"},"trusted":true},"execution_count":null,"outputs":[]}]}